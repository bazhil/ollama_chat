# **App Name**: OllamaChat

## Core Features:

- Chat UI: Implement a user interface for sending messages to the LLM and displaying responses.
- Docker Compose Configuration: Configure `docker-compose.yml` to set up the Next.js application and Ollama service to connect to the `deepseek-r1` model.
- Ollama Integration: Establish a connection to the locally running Ollama service with `deepseek-r1` from the Next.js application to send prompts and receive responses.

## Style Guidelines:

- Primary color: Neutral white or light gray for the background.
- Secondary color: Dark gray or black for text to ensure readability.
- Accent: Teal (#008080) for interactive elements like buttons and message bubbles.
- Simple, single-column layout for the chat interface to focus on readability.
- Clearly defined message bubbles to distinguish between user and AI responses.
- Clean and readable font for chat messages and UI elements.